name: 'Kustomize Apply'
description: 'Apply a built kustomize overlay to a Kubernetes cluster; waits only on workloads provided by Inspect'
author: 'KoalaOps'

branding:
  icon: 'upload-cloud'
  color: 'purple'

# Assumes Inspect ran before this step.
# - namespace and workloads_json come from Kustomize Inspect outputs.
inputs:
  overlay_dir:
    description: 'Path to kustomize overlay directory'
    required: true
  namespace:
    description: 'Kubernetes namespace to apply into (from Inspect)'
    required: true
  workloads_json:
    description: 'JSON array from Inspect: [{kind,name,namespace}]'
    required: false
    default: '[]'
  dry_run:
    description: 'Perform server-side dry run only'
    required: false
    default: 'false'
  validate:
    description: 'Validate manifests with kubectl client-side schema before apply'
    required: false
    default: 'true'
  server_side:
    description: 'Use Server-Side Apply'
    required: false
    default: 'false'
  wait:
    description: 'Wait for provided workloads to become ready'
    required: false
    default: 'true'
  wait_timeout:
    description: 'Wait timeout in seconds'
    required: false
    default: '300'

outputs:
  applied_resources_json:
    description: 'kubectl apply output lines as JSON array (best-effort)'
    value: ${{ steps.apply.outputs.applied_resources_json }}

runs:
  using: 'composite'
  steps:
    - name: Check required tools
      shell: bash
      run: |
        set -euo pipefail
        for bin in kustomize kubectl jq; do
          if ! command -v "$bin" >/dev/null 2>&1; then
            echo "::error::Required tool '$bin' not found in PATH."
            exit 1
          fi
        done
        echo "âœ… Tools present: kustomize, kubectl, jq"

    - name: Validate inputs
      shell: bash
      run: |
        set -euo pipefail
        OVERLAY="${{ inputs.overlay_dir }}"
        if [ ! -d "$OVERLAY" ] || [ ! -f "$OVERLAY/kustomization.yaml" ]; then
          echo "::error::overlay_dir invalid or missing kustomization.yaml: $OVERLAY"
          exit 1
        fi
        if [ -z "${{ inputs.namespace }}" ]; then
          echo "::error::namespace input is required (pass from Inspect)"
          exit 1
        fi
        echo "âœ… overlay_dir and namespace look good"

    - name: Build Kustomize manifests
      shell: bash
      run: |
        set -euo pipefail
        echo "ðŸ”¨ kustomize build: ${{ inputs.overlay_dir }}"
        if ! kustomize build "${{ inputs.overlay_dir }}" > /tmp/manifests.yaml 2> /tmp/kustomize.err; then
          echo "::error::kustomize build failed"
          sed -n '1,120p' /tmp/kustomize.err || true
          exit 1
        fi
        echo "âœ… Built manifests to /tmp/manifests.yaml"

    - name: Validate (client-side)
      if: inputs.validate == 'true' && inputs.dry_run != 'true'
      shell: bash
      run: |
        set -euo pipefail
        echo "âœ… Client-side schema validation"
        kubectl apply --validate=true --dry-run=client -f /tmp/manifests.yaml

    - name: Ensure namespace exists
      if: inputs.dry_run != 'true'
      shell: bash
      run: |
        set -euo pipefail
        NS="${{ inputs.namespace }}"
        echo "ðŸ“ Ensuring namespace: $NS"
        kubectl create namespace "$NS" --dry-run=client -o yaml | kubectl apply -f -

    - name: Apply
      id: apply
      shell: bash
      run: |
        set -euo pipefail
        NS="${{ inputs.namespace }}"
        DRY="${{ inputs.dry_run }}"
        SSA="${{ inputs.server_side }}"

        CMD=(kubectl apply -f /tmp/manifests.yaml -n "$NS")
        [ "$SSA" = "true" ] && CMD+=(--server-side)
        if [ "$DRY" = "true" ]; then
          echo "ðŸ” Server-side dry run"
          CMD+=(--dry-run=server)
        else
          echo "ðŸš€ Applying manifests"
        fi

        # Run once; capture both streams with real-time output
        if "${CMD[@]}" > >(tee /tmp/apply.out) 2> >(tee /tmp/apply.err >&2); then
          APPLY_SUCCESS=true
        else
          APPLY_SUCCESS=false
        fi

        # Check for immutable field errors (case-insensitive, broader pattern)
        if [ "$APPLY_SUCCESS" = "false" ] && grep -Eiq 'immutable.*field|field.*immutable' /tmp/apply.err 2>/dev/null; then
          echo ""
          echo "::error::Kubernetes detected an immutable field change"

          # Robust resource extraction with fallbacks
          RESOURCE_INFO="$(
            awk '
              match($0, /The[[:space:]]+([A-Za-z]+)[[:space:]]+"([^"]+)"/, m) {
                print m[1] " \"" m[2] "\""; found=1; exit
              }
              match($0, /([A-Za-z]+)\/([A-Za-z0-9._-]+)/, m) {
                print m[1] " \"" m[2] "\""; found=1; exit
              }
              END { if (!found) print "resource" }
            ' /tmp/apply.err
          )"

          # Parse kind and name for actionable commands
          RESOURCE_KIND="$(echo "$RESOURCE_INFO" | awk '{print $1}')"
          RESOURCE_NAME="$(echo "$RESOURCE_INFO" | sed 's/^[^ ]* "\(.*\)"$/\1/')"

          # Write detailed explanation with actual values
          {
            cat <<'MD'
## âš ï¸ Immutable Field Error

**What happened:**
Kubernetes rejected the deployment because you tried to change an immutable field (like `spec.selector` on a Deployment). These fields cannot be modified once a resource is created.

**Common causes:**
- Changed label selectors in your deployment
- Modified matchLabels in the spec.selector
- Updated immutable fields in StatefulSets or other resources

**How to fix this:**

1. **Delete the resource first, then reapply:**
MD
            echo '   ```bash'
            if [ "$RESOURCE_INFO" != "resource" ]; then
              echo "   kubectl delete $RESOURCE_KIND $RESOURCE_NAME -n $NS"
            else
              echo "   kubectl delete <kind> <name> -n $NS"
            fi
            echo "   kubectl apply -f <your-manifests>"
            echo '   ```'
            cat <<'MD'

2. **Or use a different resource name:**
   - Rename your deployment/resource
   - Deploy as a new resource
   - Remove the old one once the new one is healthy

3. **In CI/CD pipelines:**
   - Add a pre-deployment step to delete affected resources
   - Use blue/green or canary deployment strategies
   - Consider using `kubectl replace --force` (causes downtime)

**Full error output:**
```
MD
            cat /tmp/apply.err
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

          echo "::group::Full kubectl error output"
          cat /tmp/apply.err
          echo "::endgroup::"

          exit 1
        fi

        # If there were other errors, show them and exit
        if [ "$APPLY_SUCCESS" = "false" ]; then
          echo "::error::kubectl apply failed"
          cat /tmp/apply.err >&2
          exit 1
        fi

        # Best-effort JSON summary of apply results
        jq -R -s -c 'split("\n") | map(select(length>0))' /tmp/apply.out > /tmp/apply.json || echo "[]">/tmp/apply.json
        echo "applied_resources_json=$(cat /tmp/apply.json)" >> "$GITHUB_OUTPUT"
